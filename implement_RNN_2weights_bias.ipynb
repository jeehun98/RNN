{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "l12m8-hpJVEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_time_series(batch_size, n_steps):\n",
        "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
        "    time = np.linspace(0, 1, n_steps)\n",
        "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   웨이브 1\n",
        "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + 웨이브 2\n",
        "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + 잡음\n",
        "    return series[..., np.newaxis].astype(np.float32)"
      ],
      "metadata": {
        "id": "_SBKypfVPcVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size 개수만큼의 시계열 데이터가 생성\n",
        "\n",
        "각 시계열 데이터는 n_steps 만큼의 데이터가 있고,\n",
        "\n",
        "앞선 n_steps - 1 개의 데이터를 통해 n_steps 번째의 데이터를 예측한다."
      ],
      "metadata": {
        "id": "vzmvofPETGdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 1)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
        "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
        "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
      ],
      "metadata": {
        "id": "wfOMndrQQEgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_Eox7LdQ48p",
        "outputId": "b1ba678c-799f-4cba-f11f-55d95702800d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 50, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 556
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYIP9iTFRKV_",
        "outputId": "11bdd18d-1969-442e-e146-590b263b4c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 557
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mninr1wRFbE",
        "outputId": "84818ee7-0fe5-42bc-e6e8-f42578b036e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 558
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMWSqGgcJP_p"
      },
      "outputs": [],
      "source": [
        "# 활성화 함수\n",
        "class activation_function:\n",
        "  # 시그모이드 함수\n",
        "  def sigmoid(self, x):\n",
        "    return 1 / (1+np.e**-x)\n",
        "  \n",
        "  # 시그모이드 함수의 미분 함수\n",
        "  def sigmoid_diff(self, x):\n",
        "    return x * (1 - x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 비용 함수 클래스, 비용 함수의 종류에 따라 다른 클래스 내 함수를 사용한다.\n",
        "class cost_function:\n",
        "  # 예측값\n",
        "  predict = []\n",
        "  # 타겟값\n",
        "  target = []\n",
        "  # 비용 함수값\n",
        "  error_cost = []\n",
        "\n",
        "  # 오차 제곱합\n",
        "  def errer_squared_sum(self, predict, target):\n",
        "    self.predict = predict\n",
        "    self.target = target\n",
        "\n",
        "    self.error_cost = np.sum(0.5*((predict - target)**2))\n",
        "    return self.error_cost\n",
        "\n",
        "  # 오차 제곱합 미분 함수\n",
        "  def diff_error_squared_sum(self):\n",
        "    return (self.predict[0][0] - self.target[0][0])"
      ],
      "metadata": {
        "id": "Pc9UQa7iEF-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbFrbXEwCsXo"
      },
      "outputs": [],
      "source": [
        "class RNN_vector_to_sequence:\n",
        "    #입력값\n",
        "    input_data = []\n",
        "    \n",
        "    #가중치\n",
        "    weight = []\n",
        "    \n",
        "    #편향값\n",
        "    bias = []\n",
        "\n",
        "    # 입력 가중치\n",
        "    input_w = []\n",
        "\n",
        "    # 이전 출력에 대한 가중치\n",
        "    before_w = []\n",
        "\n",
        "    # 편향 값 bais\n",
        "    bias = []\n",
        "\n",
        "    # 노드 입력\n",
        "    node_input = []\n",
        "\n",
        "    # 노드 출력\n",
        "    node_output = []\n",
        "\n",
        "    # 타겟, 목푯값\n",
        "    target = []\n",
        "\n",
        "    # 활성화 함수\n",
        "    activation = activation_function()\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = cost_function()\n",
        "\n",
        "    # 예측 결과\n",
        "    predict = []\n",
        "\n",
        "    # 각 층의 델타 값의 저장\n",
        "    delta = []\n",
        "\n",
        "     # 각 가중치 업데이트 크기\n",
        "    input_weight_update = []\n",
        "\n",
        "    before_weight_update = []\n",
        "\n",
        "    def delta_to_sequence_cal_rnn_test(self, input, target):\n",
        "\n",
        "      # 타겟값의 저장\n",
        "      self.target = target\n",
        "\n",
        "      # 입력 데이터의 저장\n",
        "      self.input = input\n",
        "\n",
        "      # 입력 데이터 크기에 맞는 가중치 값이 생성되어야 한다.\n",
        "      # 입력 (3,1) 데이터에 대한 연산 결과 (1,1)를 예측한다고 가정,\n",
        "\n",
        "      # 입력값에 사용되는 가중치\n",
        "      # (3,1) 크기의 입력 데이터에 대해 (1,1) 의 행렬곱 연산 결과를 얻기 위해, (1,3) 크기의 가중치 행렬이 필요하다\n",
        "      self.input_w = np.random.rand(target.shape[0], input.shape[1])\n",
        "      \n",
        "      # 이전 출력에 대한 가중치\n",
        "      # (1,1) 노드 출력에 대해 (1,1) 의 행렬곱 연산 결과를 얻기 위한, (1,1) 크기의 가중치 행렬\n",
        "      self.before_w = np.random.rand(target.shape[0], target.shape[0])\n",
        "\n",
        "      # bias 값 생성, (1,1) 행렬에 더해지기 위한 (1,1) 크기의 bias 값 생성\n",
        "      self.bias = np.random.rand(target.shape[0], target.shape[0])\n",
        "\n",
        "      # 이전 노드의 출력, 첫 부분의 경우 이 값이 0이다. 행렬의 크기는 (1,1)\n",
        "      before = np.zeros((target.shape[0], target.shape[0]))\n",
        "\n",
        "      self.node_output.append(before)\n",
        "      \n",
        "      # (3, n) 크기의 입력 데이터에서 n 번의 반복을 수행하게 됨\n",
        "      for i in range(input.shape[0]):\n",
        "        # 노드 입력 데이터의 numpy 행렬 생성\n",
        "        input_data = input[i].reshape(input.shape[1],-1)\n",
        "\n",
        "        # RNN 노드 입력 값 계산, 이전 노드 출력 @ 가중치 + 입력 데이터 @ 가중치\n",
        "        node_input = (self.before_w @ before) + (self.input_w @ input_data) + bias\n",
        "        self.node_input.append(node_input)\n",
        "\n",
        "        # 노드 출력 계산, 활성화 함수 연산을 수행한다.\n",
        "        node_output = self.activation.sigmoid(node_input)\n",
        "        self.node_output.append(node_output)\n",
        "\n",
        "        # 타입 스텝의 출력이 다음 노드의 입력이 된다.\n",
        "        before = node_output\n",
        "\n",
        "      self.predict = node_output\n",
        "\n",
        "      self.cost_cal()\n",
        "\n",
        "      return self.predict\n",
        "\n",
        "    def cost_cal(self):\n",
        "      return self.cost.errer_squared_sum(self.predict, self.target)\n",
        "\n",
        "    \n",
        "    def cal_delta(self):\n",
        "      #마지막 노드의 변화량에 대한 오차 함수의 변화량 계산\n",
        "      delta = (self.cost.diff_error_squared_sum() * self.activation.sigmoid_diff(self.predict))\n",
        "      self.delta.append(delta)\n",
        "\n",
        "      # n개의 delta 값을 계산하기 위한 반복\n",
        "      for i in range(input.shape[0] - 1, -1, -1):\n",
        "        # 노드 출력의 변화에 대한 비용 함수의 변화량 계산\n",
        "        delta = self.before_w @ delta\n",
        "        # 활성화 함수에 따른 변화량 계산, 해당 값이 노드 변화에 대한 비용 함수의 변화량이 된다. \n",
        "        delta = delta * self.activation.sigmoid_diff(self.node_output[self.input.shape[0] - 1])\n",
        "        # 노드별 delta 값의 저장\n",
        "        self.delta.append(delta)\n",
        "    \n",
        "\n",
        "    def update_weight(self, learning_rate):\n",
        "      # 원활한 연산을 위해 마지막 노드부터 거꾸로 계산된 delta 값을 뒤집어준다.\n",
        "      self.delta = self.delta[::-1]\n",
        "\n",
        "      result = 0\n",
        "\n",
        "      # 해당 delta 값과의 데이터 입력값을 통해 input_w 의 가중치 변화량을 계산할 수 있다\n",
        "      for i in range(self.input.shape[0]):\n",
        "        result = result + self.delta[i] * self.node_input[i]\n",
        "\n",
        "      self.before_weight_update = result\n",
        "\n",
        "      # 이전 노드 출력값을 통해 before_w 의 가중치 변화량 계산\n",
        "      result = 0\n",
        "\n",
        "      for i in range(self.input.shape[0]):\n",
        "        result = result + self.delta[i] * self.input[i]\n",
        "\n",
        "      self.input_weight_update = result\n",
        "\n",
        "      # 가중치 업데이트\n",
        "      self.input_w = self.input_w - (self.input_weight_update * learning_rate)\n",
        "\n",
        "      self.before_w = self.before_w - (self.before_weight_update * learning_rate)\n",
        "\n",
        "    def iterations(self, iterations, learning_rate):\n",
        "      # 이전 노드의 출력, 첫 부분의 경우 이 값이 0이다. 행렬의 크기는 (1,1)\n",
        "      before = np.zeros((self.target.shape[0], self.target.shape[0]))\n",
        "      for j in range(iterations):\n",
        "        # 초기화\n",
        "        self.node_input = []\n",
        "        self.node_output = []\n",
        "        for i in range(input.shape[0]):\n",
        "          # 노드 입력 데이터의 numpy 행렬 생성\n",
        "          input_data = input[i].reshape(input.shape[1],-1)\n",
        "\n",
        "          # RNN 노드 입력 값 계산, 이전 노드 출력 @ 가중치 + 입력 데이터 @ 가중치\n",
        "          node_input = (self.before_w @ before) + (self.input_w @ input_data)\n",
        "          self.node_input.append(node_input)\n",
        "\n",
        "          # 노드 출력 계산, 활성화 함수 연산을 수행한다.\n",
        "          node_output = self.activation.sigmoid(node_input)\n",
        "          self.node_output.append(node_output)\n",
        "\n",
        "          # 순환 노드의 다음 노드 입력값의 계산\n",
        "          before = node_output\n",
        "\n",
        "        self.predict = before\n",
        "        self.cal_delta()\n",
        "        self.update_weight(learning_rate)\n",
        "        print(self.cost_cal(), self.predict, self.target)\n",
        "\n"
      ]
    }
  ]
}