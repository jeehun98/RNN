{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "l12m8-hpJVEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMWSqGgcJP_p"
      },
      "outputs": [],
      "source": [
        "# 활성화 함수\n",
        "class activation_function:\n",
        "  # 시그모이드 함수\n",
        "  def sigmoid(self, x):\n",
        "    return 1 / (1+np.e**-x)\n",
        "  \n",
        "  # 시그모이드 함수의 미분 함수\n",
        "  def sigmoid_diff(self, x):\n",
        "    return x * (1 - x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 비용 함수 클래스, 비용 함수의 종류에 따라 다른 클래스 내 함수를 사용한다.\n",
        "class cost_function:\n",
        "  # 예측값\n",
        "  predict = []\n",
        "  # 타겟값\n",
        "  target = []\n",
        "  # 비용 함수값\n",
        "  error_cost = []\n",
        "\n",
        "  # 오차 제곱합\n",
        "  def errer_squared_sum(self, predict, target):\n",
        "    self.predict = predict\n",
        "    self.target = target\n",
        "\n",
        "    self.error_cost = np.sum(0.5*((predict - target)**2))\n",
        "    return self.error_cost\n",
        "\n",
        "  # 오차 제곱합 미분 함수\n",
        "  def diff_error_squared_sum(self):\n",
        "    return self.predict - self.target"
      ],
      "metadata": {
        "id": "Pc9UQa7iEF-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbFrbXEwCsXo"
      },
      "outputs": [],
      "source": [
        "class RNN_vector_to_sequence:\n",
        "    #입력값\n",
        "    input_data = []\n",
        "    \n",
        "    #가중치\n",
        "    weight = []\n",
        "    \n",
        "    #편향값\n",
        "    bias = []\n",
        "\n",
        "    # 입력 가중치\n",
        "    input_w = []\n",
        "\n",
        "    # 이전 출력에 대한 가중치\n",
        "    before_w = []\n",
        "\n",
        "    # 출력 가중치\n",
        "    result_w = []\n",
        "\n",
        "    # 편향 값 bais\n",
        "    bias = []\n",
        "\n",
        "    # 노드 입력\n",
        "    node_input = []\n",
        "\n",
        "    # 노드 출력\n",
        "    node_output = []\n",
        "\n",
        "    # 타겟, 목푯값\n",
        "    target = []\n",
        "\n",
        "    # 활성화 함수\n",
        "    activation = activation_function()\n",
        "\n",
        "    # 비용 함수\n",
        "    cost = cost_function()\n",
        "\n",
        "    # 예측 결과\n",
        "    predict = []\n",
        "\n",
        "    # 각 층의 델타 값의 저장\n",
        "    delta = []\n",
        "\n",
        "     # 각 가중치 업데이트 크기\n",
        "    input_weight_update = []\n",
        "\n",
        "    before_weight_update = []\n",
        "\n",
        "    result_weight_update = []\n",
        "\n",
        "    def delta_to_sequence_cal_rnn(self, input, target, bias):\n",
        "\n",
        "      # 타겟값의 저장\n",
        "      self.target = target\n",
        "\n",
        "\n",
        "      # 입력 데이터 크기에 맞는 가중치 값이 생성되어야 한다.\n",
        "      # 입력 (3,1) 데이터에 대한 연산 결과 (1,1)를 예측한다고 가정,\n",
        "\n",
        "      # 입력값에 사용되는 가중치\n",
        "      # (3,1) 크기의 입력 데이터에 대해 (1,1) 의 행렬곱 연산 결과를 얻기 위해, (1,3) 크기의 가중치 행렬이 필요하다\n",
        "      input_w = np.random.rand(target.shape[0], input.shape[0])\n",
        "\n",
        "      # 이전 출력에 대한 가중치\n",
        "      # (1,1) 노드 출력에 대해 (1,1) 의 행렬곱 연산 결과를 얻기 위한, (1,1) 크기의 가중치 행렬\n",
        "      before_w = np.random.rand(target.shape[0], target.shape[0])\n",
        "\n",
        "      # 예측에 사용되는 가중치\n",
        "      # 노드 출력 (3,1) 에 대해 예측값 (1,1) 크기의 데이터 행렬을 얻기 위해, (1,3) 크기의 가중치 행렬이 필요하다.\n",
        "      result_w = np.random.rand(target.shape[0], input.shape[0])\n",
        "\n",
        "      # 이전 노드의 출력, 첫 부분의 경우 이 값이 0이다. 행렬의 크기는 (1,1)\n",
        "      before = np.zeros((target.shape[0], target.shape[0]))\n",
        "\n",
        "      # (3, n) 크기의 입력 데이터에서 n 번의 반복을 수행하게 됨\n",
        "      for i in range(input.shape[1]):\n",
        "        # 노드 입력 계산\n",
        "        node_input = (before_w @ before) + (input_w @ input) + bias\n",
        "        self.node_input.append(node_input)\n",
        "\n",
        "        # 노드 출력 계산\n",
        "        node_output = self.activation.sigmoid(node_input)\n",
        "        self.node_output.append(node_output)\n",
        "\n",
        "        # 순환 노드의 다음 노드 입력값의 계산\n",
        "        before = self.before_w @ node_output\n",
        "\n",
        "      self.predict = self.result_w @ node_output\n",
        "\n",
        "      return self.predict\n",
        "\n",
        "    def cal_delta(self):\n",
        "      #출력 노드의 변화량에 대한 오차 함수의 변화량 계산\n",
        "      delta = (self.cost.diff_error_squared_sum() * self.activation.sigmoid_diff(self.predict))\n",
        "      self.delta.append(delta)\n",
        "      \n",
        "      # 해당 delta 값을 통해 result_w 의 가중치 업데이트 크기를 계산할 수 있다.\n",
        "      # delta 값과 result_w 의 변화량(이전 노드의 출력) 의 계산을 통해 result_w 의 변화량을 계산한다.\n",
        "      self.result_weight_update = (delta @ self.node_output[self.input.shape[1] - 1].T).T\n",
        "\n",
        "      # 노드 출력에 대한 변화량 계산, 델타 투 시퀀스 RNN 에서는 result_w 가중치가 한 번만 사용된다.\n",
        "      # node_output_diff 는 출력층 이전 노드 출력의 변화량에 대한 비용 함수의 변화량\n",
        "      node_output_diff = (delta @ self.result_w) \n",
        "      \n",
        "      # 활성화 함수 변화량 적용\n",
        "      node_output_diff_activation = node_output_diff * self.activation.sigmoid_diff(self.node_input[self.input.shape[1] - 1])\n",
        "\n",
        "      # 노드 입력에 대한 비용 함수의 변화량\n",
        "      node_input_diff = self.node_output[self.input.shape[1] - 2] @ node_output_diff_activation \n",
        "\n",
        "      # n 개의 delta 값을 계산하기 위해 각 반복은 입력 데이터의 개수(3, n) 의 n 번 만큼 반복되어야 한다.\n",
        "      for i in range(len(self.input.shape[1]) - 2, -1, -1):\n",
        "        \n",
        "        activation_diff = self.activation.sigmoid_diff(delta)\n",
        "        # \n"
      ]
    }
  ]
}